{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print keras.__version__\n",
    "\n",
    "import tensorflow as tf\n",
    "print tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "train_path = '../Data/KITTI_train/kitti_train_3.h5'\n",
    "test_path = '../Data/KITTI_train/kitti_test_3.h5'\n",
    "def load_data(path):\n",
    "    f = h5py.File(path, 'r')\n",
    "    X_train = np.asarray(list(f['data']))\n",
    "    Y_train = np.asarray(list(f['label']))\n",
    "\n",
    "    # Normalize the data\n",
    "    for i in X_train:\n",
    "        i -= np.min(i, axis=0)\n",
    "        i[:,0] /= max(i[:,0]) - min(i[:,0])\n",
    "        i[:,1] /= max(i[:,1]) - min(i[:,1])\n",
    "        i[:,2] /= max(i[:,2]) - min(i[:,2])\n",
    "    #m = max(X_train.min(), X_train.max(), key=abs)\n",
    "    #X_train /= m # This puts the data in [0,1]\n",
    "    return X_train, Y_train\n",
    "\n",
    "X_train, Y_train = load_data(train_path)\n",
    "X_test, Y_test = load_data(test_path)\n",
    "#Y_test = [[0.0,1.0]if i[0] == 1.0 else [1.0, 0.0]  for i in Y_test]\n",
    "#Y_train = [[0.0,1.0]if i[0] == 1.0 else [1.0, 0.0]  for i in Y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.asarray(Y_test)\n",
    "Y_train = np.asarray(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print X_train.shape\n",
    "print Y_train.shape\n",
    "\n",
    "print Y_test.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_test_hist = [np.argmax(i) for i in Y_test]\n",
    "y_train_hist = [np.argmax(i) for i in Y_train]\n",
    "\n",
    "plt.hist(y_test_hist)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(y_train_hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 666\n",
    "\n",
    "print(\"Label: %s\"%(Y_train[5]))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "X,Y,Z = np.hsplit(X_train[index],3)\n",
    "scat = ax.scatter(X,Y,Z)\n",
    "\n",
    "max_range = np.asarray([X.max()-X.min(), Y.max()-Y.min(), Z.max()-Z.min()]).max()\n",
    "Xb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(X.max()-X.min())\n",
    "Yb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(Y.max()-Y.min())\n",
    "Zb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(Z.max()-Z.min())\n",
    "\n",
    "for xb,yb,zb in zip(Xb,Yb,Zb):\n",
    "    ax.plot([xb],[yb],[zb], 'r')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Reshape, Dropout\n",
    "from keras.layers import Convolution1D, MaxPooling1D, BatchNormalization\n",
    "from keras.layers import Lambda\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def mat_mul(A, B):\n",
    "    return tf.matmul(A, B)\n",
    "\n",
    "# number of points in each sample\n",
    "num_points = 1024\n",
    "\n",
    "# number of categories\n",
    "k = 3\n",
    "\n",
    "# define optimizer\n",
    "adam = optimizers.Adam(lr=0.001, decay=0.7)\n",
    "\n",
    "# ------------------------------------ Pointnet Architecture\n",
    "# input_Transformation_net\n",
    "input_points = Input(shape=(num_points, 3))\n",
    "x = Convolution1D(64, 1, activation='relu',\n",
    "                  input_shape=(num_points, 3))(input_points)\n",
    "x = BatchNormalization()(x)\n",
    "x = Convolution1D(128, 1, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Convolution1D(1024, 1, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(pool_size=num_points)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(9, weights=[np.zeros([256, 9]), np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32)])(x)\n",
    "input_T = Reshape((3, 3))(x)\n",
    "\n",
    "# forward net\n",
    "g = Lambda(mat_mul, arguments={'B': input_T})(input_points)\n",
    "g = Convolution1D(64, 1, input_shape=(num_points, 3), activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "g = Convolution1D(64, 1, input_shape=(num_points, 3), activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "\n",
    "# feature transform net\n",
    "f = Convolution1D(64, 1, activation='relu')(g)\n",
    "f = BatchNormalization()(f)\n",
    "f = Convolution1D(128, 1, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Convolution1D(1024, 1, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = MaxPooling1D(pool_size=num_points)(f)\n",
    "f = Dense(512, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Dense(256, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Dense(64 * 64, weights=[np.zeros([256, 64 * 64]), np.eye(64).flatten().astype(np.float32)])(f)\n",
    "feature_T = Reshape((64, 64))(f)\n",
    "\n",
    "# forward net\n",
    "g = Lambda(mat_mul, arguments={'B': feature_T})(g)\n",
    "g = Convolution1D(64, 1, activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "g = Convolution1D(128, 1, activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "g = Convolution1D(1024, 1, activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "\n",
    "# global_feature\n",
    "global_feature = MaxPooling1D(pool_size=num_points)(g)\n",
    "\n",
    "\n",
    "\n",
    "# point_net_cls\n",
    "c = Dense(512, activation='relu')(global_feature)\n",
    "c = BatchNormalization()(c)\n",
    "c = Dropout(rate=0.7)(c)\n",
    "c = Dense(256, activation='relu')(c)\n",
    "c = BatchNormalization()(c)\n",
    "c = Dropout(rate=0.7)(c)\n",
    "c = Dense(k, activation='softmax')(c)\n",
    "prediction = Flatten()(c)\n",
    "# --------------------------------------------------end of pointnet\n",
    "\n",
    "# print the model summary\n",
    "model = Model(inputs=input_points, outputs=prediction)\n",
    "print(model.summary())\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train, Y_train = shuffle(X_train, Y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train, y=Y_train, batch_size=32, \n",
    "                    epochs=10, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print model.evaluate(X_train, Y_train)\n",
    "print model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import os\n",
    "#model_json = model.to_json()\n",
    "#with open(\"voxnet_kitti.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"pointnet_kitti.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
